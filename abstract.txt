Artificial intelligence agents for games such as Chess and Go have seen tremendous success over the last years, surpassing human ability using a stochastic algorithm called Monte Carlo tree search. Monte Carlo tree search simulates an entire game of player / opponent actions to build up utility expectations on these actions. Performing thousands of playouts is usually faster than going through an entire game tree for non trivial games, but the agent's ability does not significantly drop. Researchers hope that these systems can shed light on a general form of artificial intelligence. A substantial amount of work has been done on MCTS in perfect information environments, but real world applications require the use of non-determinism and imperfect information. This research seeks to provide more insight as to how MCTS performs in these environments, specifically the card game Euchre. This project creates a vanilla MCTS implementation in the language Go (previously sparse support) and evaluates its performance against a rule based algorithm and a random baseline. The agent accounts for hidden information by randomly sampling possible opponent hands given the information gained from previous play. The MCTS algorithm then simulates 5000 games across 50 possible determinizations and chooses the move with the highest expected utility across determinizations. When simulating games the agent must account for an exploration / exploitation trade-off, where an agents wants to perform as it knows best, but must also explore and learn. This is handled by the standard UCB (upper confidence bound) algorithm. The 3 agents were then evaluated through comparison to optimal players with no hidden information. A dataset of 1000 euchre games and their outcomes given optimal players and open hands was created. For each of these games, optimal players were then swapped out with a non-optimal player without perfect information. Results show that the vanilla MCTS implementation with no domain adaptation outperforms the rule based agent and random baseline. The MCTS implementation achieves an optimal outcome nearly 10% more than the rule based approach, supporting that the base MCTS algorithm is generalizable to both deterministic and non-deterministic domains.
